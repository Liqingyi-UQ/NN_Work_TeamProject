import random
random.seed(112358)

import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

from sklearn.inspection import permutation_importance
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.utils import resample

# preprocessing
from sklearn import preprocessing 

# TensorFlow and tf.keras
import tensorflow as tf

# Some modules added
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import zipfile

%matplotlib inline
# 1.1
# your code here 
# Read the dataset
df = pd.read_csv("flights.csv")
# Delete the value of airport is digit (Noise)
rows_to_drop = df[df['ORIGIN_AIRPORT'].str.isdigit() & df['DESTINATION_AIRPORT'].str.isdigit()].index
df.drop(rows_to_drop, inplace=True)

# Create a variable DELAY_OR_NOT that denotes whether ARRIVAL_DELAY is greater than or equal to 15 minutes
# if delayed, 1; else, 0
df['DELAY_OR_NOT'] = np.where(df['ARRIVAL_DELAY'] >= 15, 1, 0)
# Drop ARRIVAL_DELAY, because it has been label
df.drop('ARRIVAL_DELAY', axis=1, inplace=True)

# 1.1.2
# your code here
# preprocess the data
# Having checked the data by hand, there is no missing value
categorical_features = ['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT']

# one-hot-encode the non-numeric categorical variables
enc = preprocessing.OneHotEncoder(sparse=False)
encoded_features = enc.fit_transform(df[categorical_features])

# change the result to dataFrame. easy to check and concat
# Notice: old version sklearn using get_feature_names function
columns = enc.get_feature_names(categorical_features)
encoded_df_part = pd.DataFrame(encoded_features, columns=enc.get_feature_names(categorical_features))
df.drop(columns=categorical_features, inplace=True)

# Make sure index alignment
df = df.reset_index(drop=True)
encoded_df_part = encoded_df_part.reset_index(drop=True)

df = pd.concat([df, encoded_df_part], axis=1)

# Get predictors and response
predictors = df.drop(columns=['DELAY_OR_NOT'])
response = df['DELAY_OR_NOT']

# split the data into training and test sets.
X_train, X_test, y_train, y_test = train_test_split(predictors, response, test_size=0.2, random_state=111)

# scale the data and print
# Do not scale y because values of y are 0 and 1
X_train_scaled = StandardScaler().fit_transform(X_train)
X_test_scaled = StandardScaler().fit_transform(X_test)
print(f"X_train shape: {X_train_scaled.shape}")
print(f"X_test shape: {X_test_scaled.shape}")
print(f"y_train : {y_train.shape}")
print(f"y_test : {y_test.shape}")

# 1.2
# build your NN 
# your code here
NN_model = Sequential(name="NN_model")
NN_model.add(Dense(200, activation="relu", kernel_regularizer=keras.regularizers.l1_l2(l1=0.002, l2=0.002),
                   input_shape=(X_train_scaled.shape[1],)))
NN_model.add(Dropout(0.3))
NN_model.add(Dense(200,kernel_regularizer=keras.regularizers.l1_l2(l1=0.002, l2=0.002), activation="relu"))
NN_model.add(Dropout(0.3))
NN_model.add(Dense(1, activation="sigmoid"))


# compile it and run it
# your code here 
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
NN_model.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])
history = NN_model.fit(X_train_scaled, y_train, batch_size=64, epochs=50, validation_split=0.2,
                       callbacks=[early_stopping])

# plot train and val acc as  a function of epochs
# your code here
plt.title('Model Accuracy')
plt.plot(history.history['accuracy'], label='Train Accuracy', color='#FF9A98')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='#75B594')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.show()

# primer to print: 
# print("NN_model_train_auc:", roc_auc_score(y_train, y_hat))
# your code here 
y_train_predict_pro = NN_model.predict(X_train_scaled)
train_auc = roc_auc_score(y_train, y_train_predict_pro)
print(f"NN_model_train_auc: {train_auc:.4f}")

# your code here

# 1.3
# Fit the logistic regression model
# your code here
# replace the actual response values with the predicted
# values generated by the fitted NN_model
proxy_X_train = X_train_scaled
# pro > 0, the result is 'yes', else 'no'
proxy_y_train = np.where(NN_model.predict(X_train_scaled) > 0.5, 1, 0)
# original proxy_y_train is two-dimensional
proxy_y_train = proxy_y_train.reshape(-1)

# build the model and print the test accuracy
logreg = LogisticRegression(penalty='l2', C=100, solver='lbfgs', max_iter=1000)
logreg.fit(proxy_X_train, proxy_y_train)
proxy_y_test_pred = logreg.predict(X_test_scaled)
proxy_test_accuracy = accuracy_score(y_test, proxy_y_test_pred)
print(f"Logistic Regression Test Accuracy: {proxy_test_accuracy:.4f}")
# The result of local environment is
# NN_model_train_auc: 0.9994
# Logistic Regression Test Accuracy: 0.9802

# 1.4
# 1.4.1
# your code here
def process_data(X_train, feature_1, feature_2=None):
    """
    process data: Set all predictors to their means/modes except for special feature
    parameter:
    X_train: original train data
    feature_1: 'SCHED_DEP_HOUR'
    feature_2: second feature should be kept for real(optional)
    return:
    X_processed: the data processed
    """
    # process the original data, and get the train data
    # set predictors to their modes, there will not one-hot-encoded first
    X_processed = X_train.copy()
    non_one_hot_cols = ['DISTANCE', 'SCHEDULED_TIME', 'MONTH', 'SCHED_DEP_HOUR', 'SCHED_ARR_HOUR',
                        'FLIGHT_COUNT', 'DAY_OF_WEEK']
    # deal with the numerical data
    if feature_2 is not None:
        numeric_cols = X_train.select_dtypes(include=[np.number]).columns.difference([feature_1, feature_2])
    else:
        numeric_cols = X_train.select_dtypes(include=[np.number]).columns.difference([feature_1])

    X_processed[numeric_cols] = X_train[numeric_cols].mean()

    # deal with the category data(one-hot-encoded)
    one_hot_cols = X_train.columns.difference(non_one_hot_cols)
    X_processed[one_hot_cols] = X_train[one_hot_cols].mode().iloc[0]


    # Keep the original values of feature_1 (and feature_2 if applicable) for plotting
    X_original = X_processed.copy()

    # Standardize the data
    X_processed = StandardScaler().fit_transform(X_processed)

    return X_processed, X_original

def predict_and_plot(model, X_processed, feature_1, feature_2=None):
    """
    Using NN model to predict and plot the predicted probabilities vs features
    parameter::
    model: NN model
    X_processed: the data processed
    feature_1: the first feature kept true value
    feature_2: the second feature kept true value
    """
    # predict
    predicted_pro = model.predict(X_processed)

    # plot
    if feature_2:
        plt.scatter(X_processed[feature_1], X_processed[feature_2], c=predicted_pro, cmap='viridis',
                    alpha=0.75)
        plt.colorbar(label='Predicted Probability of Delay')
        plt.xlabel(feature_1)
        plt.ylabel(feature_2)
        plt.title(f'Predicted Delay Probability vs. {feature_1} and {feature_2}')
        plt.show()
    else:
        plt.scatter(X_processed[feature_1], predicted_pro, c=predicted_pro, cmap='viridis',
                    alpha=0.75)
        plt.colorbar(label='Predicted Probability of Delay')
        plt.xlabel(feature_1)
        plt.ylabel('Predicted Probability of Delay')
        plt.title(f'Predicted Delay Probability vs. {feature_1}')
        plt.show()

X_processed_1, X_original_1 = process_data(X_train, 'SCHED_DEP_HOUR')
predict_and_plot(NN_model, X_processed_1, X_original_1, 'SCHED_DEP_HOUR')

解释
The chart shows that as the scheduled departure time (SCHED_DEP_HOUR) increases, the probability of a flight being delayed decreases. 
The probability of delays is higher from the midnight to early morning hours, while the probability of delays decreases significantly towards the afternoon and evening hours

# 1.4.2
# your code here
X_processed_2, X_original_2 = process_data(X_train, 'SCHED_DEP_HOUR', 'FLIGHT_COUNT')
predict_and_plot(NN_model, X_processed_2,X_original_2, 'SCHED_DEP_HOUR', 'FLIGHT_COUNT')

# 1.4.3
# your code here
X_processed_3, X_original_3 = process_data(X_train, 'SCHED_DEP_HOUR', 'SCHED_ARR_HOUR')
predict_and_plot(NN_model, X_processed_3, X_original_3, 'SCHED_DEP_HOUR', 'SCHED_ARR_HOUR')

# 1.4.4
# your code here
X_processed_4, X_original_4 = process_data(X_train, 'SCHED_DEP_HOUR', 'DISTANCE')
predict_and_plot(NN_model, X_processed_4, X_original_4, 'SCHED_DEP_HOUR', 'DISTANCE')

解释
1. Flight delays are related to departure time and number of flights: the probability of delay is higher in the morning, especially when there are more flights, the probability of delay increases significantly. 
2. When departure and arrival times are both early (such as early morning to morning), the probability of delay is higher; and when departure and arrival times are later, the probability of delay decreases. 
3. The probability of delay varies with departure time, but is less correlated with distance

# 1.5
def progressbar(n_step, n_total):
    """Prints self-updating progress bar to stdout to track for-loop progress
    
    There are entire 3rd-party libraries dedicated to custom progress-bars.
    A simple function like this is often more than enough to get the job done.
    
    :param n_total: total number of expected for-loop iterations
    :type n_total: int
    :param n_step: current iteration number, starting at 0
    :type n_step: int

    .. example::
    
        for i in range(n_iterations):
            progressbar(i, n_iterations)
            
    .. source:
    
        This function is a simplified version of code found here:
        https://stackoverflow.com/questions/3160699/python-progress-bar/15860757#15860757
    """
    n_step = n_step + 1
    barlen = 50
    progress = n_step / n_total
    block = int(round(barlen * progress))
    status = ""
    if n_step == n_total:
        status = "Done...\r\n\n"
    text = "\r [{0}] {1}/{2} {3}".format(
        "=" * block + "-" * (barlen - block),
        n_step,
        n_total,
        status,
    )
    sys.stdout.write(text)
    sys.stdout.flush()

%%time
# Bootstrap and train your networks and get predictions on fixed X test
# your code here
# the number of bootstrap
bootstraps=50
# 存储每次Bootstrap的模型预测
test_predictions = np.zeros((bootstraps, X_test_scaled.shape[0]))

for i in range(bootstraps):
    #跟踪bootstrap进度
    progressbar(i, bootstraps)
    X_bootstrap, y_bootstrap = resample(X_train_scaled, y_train, random_state=i)
    # 创建新的神经网络模型（和原来的结构一样）
    NN_model2 = Sequential(name="NN_model2")
    NN_model2.add(Dense(200, activation="relu", kernel_regularizer=keras.regularizers.l1_l2(l1=0.002, l2=0.002),
                   input_shape=(X_train_scaled.shape[1],)))
    NN_model2.add(Dropout(0.3))
    NN_model2.add(Dense(200,kernel_regularizer=keras.regularizers.l1_l2(l1=0.002, l2=0.002), activation="relu"))
    NN_model2.add(Dropout(0.3))
    NN_model2.add(Dense(1, activation="sigmoid"))
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    NN_model2.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])
    NN_model2.fit(X_bootstrap, y_bootstrap, batch_size=64, epochs=50, validation_split=0.2,
                       callbacks=[early_stopping])
    # 预测测试集并存储结果
    test_predictions[i, :] = NN_model2.predict(X_test_scaled).flatten()
#跟踪结束
progressbar(bootstraps, bootstraps)
#随机选择八个test样本
selected = np.random.choice(X_test_scaled.shape[0], size=8, replace=False)

# generate your plot
# your code here
#绘制预测概率分布
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10), constrained_layout=True)

for i, ax in enumerate(axes.flatten()):
    test_index = selected[i]
    sns.histplot(test_predictions[:, test_index], kde=True, ax=ax)
    ax.set_title(f"Test observation #{test_index}\nTrue Class: {y_test.iloc[test_index]}")
    ax.set_xlabel("Predicted Probability")
    ax.set_ylabel("Density")

    # 计算95%置信区间
    lower_bound = np.percentile(test_predictions[:, test_index], 2.5)
    upper_bound = np.percentile(test_predictions[:, test_index], 97.5)

    # 显示95%置信区间
    ax.axvline(x=lower_bound, color='red', linestyle='--')
    ax.axvline(x=upper_bound, color='red', linestyle='--')
    ax.text(x=lower_bound, y=ax.get_ylim()[1]*0.7, s=f"2.5%: {lower_bound:.2f}", color='red')
    ax.text(x=upper_bound, y=ax.get_ylim()[1]*0.7, s=f"97.5%: {upper_bound:.2f}", color='red')

plt.suptitle('Distribution of Predicted Probabilities with 95% Confidence Intervals')
plt.show()

# 1.5此处要写解释

# 1.6
# your code here
# 计算每个测试数据的平均预测概率
mean_test_predictions = np.mean(test_predictions, axis=0)

# 计算后验预测比率（PPR）
PPR_values = np.mean(test_predictions > 0.5, axis=0)

# 正确分类的测试数据数量
n_correct = np.sum((mean_test_predictions > 0.5) == y_test)

# 初始模型的准确性
initial_test_accuracy = n_correct / len(y_test)
print(f"Initial Test Accuracy: {initial_test_accuracy:.4f}")

thresholds = np.linspace(0, 0.5, 51)
accuracies = []
proportions_predicted = []

# 对于每个阈值，计算弃权模型的准确性和预测比例
for threshold in thresholds:
    # 选择PPR小于等于阈值的测试数据点
    mask = PPR_values <= threshold
    valid_predictions = mean_test_predictions[mask]
    valid_y_test = y_test[mask]

    # 计算准确性
    valid_n_correct = np.sum((valid_predictions > 0.5) == valid_y_test)
    valid_accuracy = valid_n_correct / len(valid_y_test) if len(valid_y_test) > 0 else None
    #计算比例
    proportion_predicted = np.sum(mask) / len(y_test)
    #存储数据
    accuracies.append(valid_accuracy)
    proportions_predicted.append(proportion_predicted)

# 绘制测试准确性变化图
plt.figure(figsize=(10, 6))
plt.plot(thresholds, accuracies, label='Test Accuracy')
plt.xlabel('PPR Threshold')
plt.ylabel('Test Accuracy')
plt.title('Test Accuracy vs. PPR Threshold')
plt.legend()
plt.show()

# 绘制预测比例变化图
plt.figure(figsize=(10, 6))
plt.plot(thresholds, proportions_predicted, label='Proportion Predicted', color='orange')
plt.xlabel('PPR Threshold')
plt.ylabel('Proportion of Predictions Made')
plt.title('Proportion of Predictions Made and PPR Threshold')
plt.legend()
plt.show()

# 我所看到的：I found that as the PPR threshold decreases, i have to balance between the accuracy of predictions and the number of points predicted. 
lower PPR thresholds typically improves the accuracy of predictions but also means giving up making predictions for certain test observations. 
Conversely, as the PPR threshold increases, the model makes predictions on more observation, but these predictions are less accurate.
# 1.6此处要写解释

# 2.1
# your code here
#Load the dataset
with zipfile.ZipFile('data/Homework 1 - Homework 1 Data.zip', 'r') as zip_ref:
    with zip_ref.open('HW1-Data/kmnist_train.csv') as file:
        train_data = pd.read_csv(file)    

#Separate images and lables
images = train_data.iloc[:, :-1].values     
labels = train_data.iloc[:, -1].values      

# Select the first '0' and '1' sample for visualization
image_0 = images[labels == 0][0].reshape(28, 28)    
image_1 = images[labels == 1][0].reshape(28, 28)   

# Display a handwritten 0 and a handwritten 1 images
plt.figure(figsize=(6, 3))
plt.subplot(1, 2, 1)
plt.title("Handwritten 0")
plt.imshow(image_0, cmap='gray')
plt.axis('off')
plt.subplot(1, 2, 2)
plt.title("Handwritten 1")
plt.imshow(image_1, cmap='gray')
plt.axis('off')
plt.show()

# 2.2
# your code here
# Split data into training and validation sets
X1_train, X1_val, Y1_train, Y1_val = train_test_split(images, labels, test_size=0.3, random_state=42)

# Build the overfitting model
model_overfit = tf.keras.Sequential([
    tf.keras.layers.Dense(100, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])    

# Compile the model
model_overfit.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history_overfit = model_overfit.fit(X1_train, Y1_train, epochs=2000, batch_size=128, validation_data=(X1_val, Y1_val))

model_overfit.summary()

# Plot the training and validation accuracy
plt.plot(history_overfit.history['accuracy'], label='Training Accuracy')
plt.plot(history_overfit.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Overfitting Model: Training vs Validation Accuracy')
plt.show()

# 2.2此处要写解释

# 2.3.1
# your code here
# Build a regularized ANN with dropout & L2 regularization
model = tf.keras.Sequential([    
    tf.keras.layers.Dense(100, activation='relu', input_shape=(784,), kernel_regularizer=tf.keras.regularizers.l2(0.005)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.005)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Define early stopping callback to avoid the overfitting
callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=60,restore_best_weights=True, verbose=1)

# Train the regularized model
history = model.fit(X1_train, Y1_train, batch_size=128, epochs=2000, validation_data=(X1_val, Y1_val), callbacks=[callback])

# Model summary
model.summary()

# Training and validation accuracy and loss
final_train_acc = history.history['accuracy'][-1]
final_val_acc = history.history['val_accuracy'][-1]
final_train_loss = history.history['loss'][-1]
final_val_loss = history.history['val_loss'][-1]

# 2.3.2
# your code here
# Difference between the training and validation accuracies and losses
print("Difference between training and validation accuracies:", final_train_acc - final_val_acc)
print("Difference between training and validation loss:", final_train_loss - final_val_loss)


# 2.3.3
# your code here
# Plot the training accuracy and validation accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Regularized Model: Training vs Validation Accuracy')
plt.show()

# 2.3.4
# your code here
# Evaluate the regularized model on test set
with zipfile.ZipFile('data/Homework 1 - Homework 1 Data.zip', 'r') as zip_ref:
    with zip_ref.open('HW1-Data/kmnist_test.csv') as file:
        test_data = pd.read_csv(file) 
x_test = test_data.iloc[:, :-1].values
y_test = test_data.iloc[:, -1].values

test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Test accuracy:", test_accuracy)
